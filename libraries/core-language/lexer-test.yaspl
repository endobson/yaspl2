#:module (core-language lexer-test)
#:import {
  (core-language lexer)
  (data lifted-primitives)
  (data source-location)
  (either)
  (list)
  (maybe)
  (prim)
  (yunit)
}
(export
  (#:values main))
(types)

(define (lex-all [bytes : Bytes]) : (Either Bytes (List (SourceSpanAnnotated Token)))
  (lex-all/run (make-core-lexer (sourced-bytes (unnamed-source) bytes)) (empty)))

(define (lex-all/run [lexer : (Lexer Token)] [tokens : (List (SourceSpanAnnotated Token))])
  : (Either Bytes (List (SourceSpanAnnotated Token)))
  (case (run-lexer lexer)
    [(lex-result v lexer) (lex-all/run lexer (cons v tokens))]
    [(end-of-input _) (right (reverse tokens))]
    [(bad-input msg _) (left msg)]))

(define (count-tokens [bytes : Bytes] [expected-count : Int]) : (-> (Maybe FailedAssertion))
  (lambda ()
    ((expect-equal (eq/either (eq/bytes) (eq/int)))
     (case (lex-all bytes)
       [(left msg) (left msg)]
       [(right tokens) (right (lifted-int (length tokens)))])
     (right (lifted-int expected-count)))))

(define (main [args : Bytes] [stdin : InputPort] [stdout : OutputPort] [stderr : OutputPort]) : Int
  (yunit/main stderr
    (varargs list
      (test-case #"parens" (count-tokens #"()[]<>{}" 8))
      (test-case #"comparisions" (count-tokens #"< == > <= >=" 5))
      (test-case #"math operations" (count-tokens #"+ - * /" 4))
      (test-case #"keywords" (count-tokens #"#:module #:define_function" 2))
      (test-case #"keyword identifiers" (count-tokens #"as while if" 3))
      (test-case #"identifiers" (count-tokens #"arr_size next_base_pointer int64" 3))
      (test-case #"not identifier" (count-tokens #"arr-size" 3))
      (test-case #"numbers" (count-tokens #"#x80 12" 2))
      )))
